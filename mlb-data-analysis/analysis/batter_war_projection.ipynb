{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4200ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from analysis.utils import clean_player_name\n",
    "from data_sources import PyBaseball, MLBStatsAPI, Salary\n",
    "from analysis.batter_data_structure import KEEP_RENAME_MAP, ROLLING_COLS\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "py_baseball = PyBaseball()\n",
    "mlb_api = MLBStatsAPI()\n",
    "\n",
    "payroll_source_paths = {\n",
    "    \"historical\": os.getenv(\"MLB_PAYROLLS\"),\n",
    "    \"recent\": os.getenv(\"MLB_PAYROLLS_2025\")\n",
    "}\n",
    "\n",
    "salary_source_paths = {\n",
    "    \"historical\": os.getenv(\"MLB_PLAYER_SALARY_DATA\")\n",
    "}\n",
    "\n",
    "salary = Salary(payroll_source_paths=payroll_source_paths, salary_source_paths=salary_source_paths)\n",
    "payrolls = salary.payroll()\n",
    "\n",
    "# Contains matching keys between data sources\n",
    "# May be helpful down the road\n",
    "# chadwick = py_baseball.player_search.chadwick()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING, force=True)  # force=True resets handlers in Jupyter (Py3.8+)\n",
    "\n",
    "for name in (\"urllib3\", \"urllib3.connectionpool\", \"requests\"):\n",
    "    logging.getLogger(name).setLevel(logging.ERROR)\n",
    "    logging.getLogger(name).propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0885ca1",
   "metadata": {},
   "source": [
    "### Utils and Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f7c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLLING_PERIOD = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f93c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_and_rename(df: pd.DataFrame, rename_map: dict):\n",
    "    df = df[list(rename_map.keys())].rename(columns=rename_map)\n",
    "    return df\n",
    "\n",
    "def _reformat_statcast_name(name: str):\n",
    "    name_split = name.split(\", \")\n",
    "    return f\"{name_split[-1]} {name_split[0]}\"\n",
    "\n",
    "def _aggregate_over_season_bref(bref_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (\n",
    "        bref_data\n",
    "        .groupby([\"season\", \"mlb_id\"])\n",
    "        .agg({\n",
    "            \"player_name\": \"first\",\n",
    "            \"team\": lambda x: \"/\".join(x.unique()),   # teams played for that season\n",
    "            \"salary\": \"sum\",\n",
    "            \"bWAR\": \"sum\",\n",
    "        })\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933236c",
   "metadata": {},
   "source": [
    "### Batters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045b656",
   "metadata": {},
   "source": [
    "Standard compile standard batter stats from fangraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ba5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_batter_stats_data_preprocessing(season: int, batter_stats_collection: dict) -> dict:\n",
    "    batter_stats = py_baseball.batter.stats(start_season=season)\n",
    "    batter_stats = _filter_and_rename(batter_stats, KEEP_RENAME_MAP[\"stats\"])\n",
    "    # Used to obtain the player salaries\n",
    "    batter_bwar = py_baseball.batter.bref_war(season=season)\n",
    "    batter_bwar = _filter_and_rename(\n",
    "        batter_bwar, \n",
    "        KEEP_RENAME_MAP[\"bref_war\"]\n",
    "    )\n",
    "    \n",
    "    batter_bwar[\"player_name\"] = batter_bwar[\"player_name\"].apply(clean_player_name)\n",
    "    batter_bwar = _aggregate_over_season_bref(batter_bwar)\n",
    "\n",
    "    batter_stats = (\n",
    "        batter_stats\n",
    "        .merge(\n",
    "            batter_bwar, \n",
    "            how=\"left\", \n",
    "            on=[\"player_name\", \"team\", \"season\"] # I'm hoping this is enough information to make a good merge\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # For now assume that na values are league minimum\n",
    "    league_minimum = salary.league_minimum_salaries(season)\n",
    "    batter_stats[\"salary\"] = batter_stats[\"salary\"].fillna(np.float64(league_minimum))\n",
    "    batter_stats[\"salary\"] = batter_stats[\"salary\"].replace(0.0, np.float64(league_minimum))\n",
    "    \n",
    "    return batter_stats_collection | {season: batter_stats}\n",
    "\n",
    "start_season, end_season = 2009, 2025\n",
    "\n",
    "batter_stats = {}\n",
    "for season in range(start_season, end_season + 1):\n",
    "    batter_stats = standard_batter_stats_data_preprocessing(season, batter_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43df8b0",
   "metadata": {},
   "source": [
    "Compile statcast data.\n",
    "\n",
    "Data is made up of:\n",
    "* Statcast expected stats: e.g. expected batting average\n",
    "* Statcast percentile rankings: e.g. sprint speed percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a8580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_batter_statcast_preprocessing(season: int, batter_statcast_collection: dict) -> dict:\n",
    "    batter_statcast_expected = py_baseball.batter.statcast_expected_stats(season)\n",
    "    batter_statcast_expected = _filter_and_rename(batter_statcast_expected, KEEP_RENAME_MAP[\"statcast_exp\"])\n",
    "\n",
    "    batter_statcast_percentile = py_baseball.batter.statcast_percentile_ranks(season)\n",
    "    batter_statcast_percentile = _filter_and_rename(batter_statcast_percentile, KEEP_RENAME_MAP[\"statcast_pct\"])\n",
    "\n",
    "    statcast = batter_statcast_expected.merge(\n",
    "        batter_statcast_percentile, \n",
    "        how=\"left\", \n",
    "        on=[\"statcast_id\"]\n",
    "    )\n",
    "\n",
    "    statcast = statcast.dropna(subset=\"player_name\")\n",
    "\n",
    "    statcast[\"player_name\"] = statcast[\"player_name\"].apply(\n",
    "        lambda player_name: _reformat_statcast_name(player_name)\n",
    "    )\n",
    "\n",
    "    statcast[\"season\"] = season\n",
    "    \n",
    "    statcast = statcast.reset_index(drop=True)\n",
    "    return batter_statcast_collection | {season: statcast}\n",
    "\n",
    "\n",
    "start_season, end_season = 2015, 2025\n",
    "\n",
    "batter_statcast = {}\n",
    "for season in range(start_season, end_season + 1):\n",
    "    batter_statcast = standard_batter_statcast_preprocessing(season, batter_statcast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b3ab2",
   "metadata": {},
   "source": [
    "### Concatenate all batter data from fangraphs and statcast, and calculate rolling averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a17df92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all batter stats\n",
    "all_batter_stats = pd.concat(\n",
    "    list(batter_stats.values()),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "\n",
    "# Combine all Statcast stats\n",
    "all_statcast_stats = pd.concat(\n",
    "    list(batter_statcast.values()),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Columns in Statcast but not in FA stats (plus season)\n",
    "statcast_cols = (\n",
    "    [col for col in all_statcast_stats.columns\n",
    "     if col not in all_batter_stats.columns]\n",
    "    + [\"season\"]\n",
    ")\n",
    "\n",
    "# Merge free agent batter stats with statcast stats\n",
    "all_batter_stats = all_batter_stats.merge(\n",
    "    all_statcast_stats[statcast_cols],\n",
    "    how=\"left\",\n",
    "    left_on=[\"mlb_id\", \"season\"],\n",
    "    right_on=[\"statcast_id\", \"season\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2ee72",
   "metadata": {},
   "source": [
    "Compute rolling statistics for numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422ea5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_statistics(df, groupby_col=\"fg_id\", rolling_period=ROLLING_PERIOD, rolling_cols=ROLLING_COLS):\n",
    "    \"\"\"Compute rolling statistics\"\"\"\n",
    "    for col in rolling_cols:\n",
    "        df[f\"{col}_{rolling_period}yr_rolling\"] = (\n",
    "            df\n",
    "            .groupby(groupby_col)[col]\n",
    "            .rolling(window=rolling_period, min_periods=None)\n",
    "            .mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def shift_targets_up(df, targets, groupby_col=\"fg_id\"):\n",
    "    \"\"\"Shift the next years war to the previous year\"\"\"\n",
    "    for col in targets:\n",
    "        df[f\"target_{col}\"] = (\n",
    "            df\n",
    "            .groupby(groupby_col)\n",
    "            [col].shift(-1)\n",
    "        )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4596fe",
   "metadata": {},
   "source": [
    "Separate pre-statcast data and post-statcast free agent statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826b46c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batter_stats = calculate_rolling_statistics(all_batter_stats)\n",
    "\n",
    "all_batter_stats = shift_targets_up(all_batter_stats, [\"fWAR\", \"bWAR\"])\n",
    "\n",
    "pre_statcast_drop_cols = [\n",
    "    col for col in all_batter_stats.columns \n",
    "    if col.replace(f\"_{ROLLING_PERIOD}yr_rolling\", \"\") in statcast_cols\n",
    "]\n",
    "\n",
    "pre_statcast = all_batter_stats[all_batter_stats[\"season\"] < 2015].drop(pre_statcast_drop_cols, axis=1)\n",
    "post_statcast = all_batter_stats[all_batter_stats[\"season\"] >= 2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d74a4",
   "metadata": {},
   "source": [
    "Build and apply the XGBRegressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536ad058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['bat_speed_3yr_rolling' 'squared_up_rate_3yr_rolling'\n",
      " 'swing_length_3yr_rolling']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['bat_speed_3yr_rolling' 'squared_up_rate_3yr_rolling'\n",
      " 'swing_length_3yr_rolling']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['bat_speed_3yr_rolling' 'squared_up_rate_3yr_rolling'\n",
      " 'swing_length_3yr_rolling']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_fWAR:\n",
      "MAE:  0.880\n",
      "RMSE: 1.268\n",
      "R²:   0.346\n",
      "--------------------\n",
      "target_bWAR:\n",
      "MAE:  0.927\n",
      "RMSE: 1.363\n",
      "R²:   0.327\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['bat_speed_3yr_rolling' 'squared_up_rate_3yr_rolling'\n",
      " 'swing_length_3yr_rolling']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "exclude_cols = [\"player_name\", \"fg_id\", \"target_fWAR\", \"target_bWAR\"]\n",
    "categorical_cols = [\"team\"] \n",
    "numeric_cols = [\n",
    "    col for col in post_statcast.columns \n",
    "    if col not in exclude_cols \n",
    "    and col not in categorical_cols\n",
    "]\n",
    "\n",
    "def build_pre_transformer(numeric_cols, categorical_cols):\n",
    "    return ColumnTransformer([\n",
    "        # 1. Base numeric: impute + scale\n",
    "        (\n",
    "            \"numeric\",\n",
    "            Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "            ]),\n",
    "            numeric_cols,\n",
    "        ),\n",
    "\n",
    "        # 2. Base categorical: one-hot\n",
    "        # (\n",
    "        #     \"base_cat\",\n",
    "        #     OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "        #     categorical_cols,\n",
    "        # )\n",
    "    ])\n",
    "\n",
    "\n",
    "results = defaultdict(dict)\n",
    "models = defaultdict(dict)\n",
    "\n",
    "targets = [\"target_fWAR\", \"target_bWAR\"]\n",
    "\n",
    "target_pool = post_statcast.dropna(subset=[\"target_bWAR\", \"target_fWAR\"]).reset_index(drop=True)\n",
    "\n",
    "X = target_pool.drop(exclude_cols, axis=1)\n",
    "\n",
    "for target in targets:\n",
    "    pre = build_pre_transformer(numeric_cols, categorical_cols)\n",
    "    \n",
    "    model = Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"est\", XGBRegressor(n_estimators=800, max_depth=6))\n",
    "    ])\n",
    "    y = target_pool[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Save model\n",
    "    models[target] = model\n",
    "\n",
    "    # Save results\n",
    "    results[target][\"mae\"] = mae\n",
    "    results[target][\"rmse\"] = rmse\n",
    "    results[target][\"r2\"] = r2\n",
    "\n",
    "    print(f\"{target}:\")\n",
    "    print(f\"MAE:  {mae:,.3f}\")\n",
    "    print(f\"RMSE: {rmse:,.3f}\")\n",
    "    print(f\"R²:   {r2:.3f}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54a6aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[\"target_fWAR\"]\n",
    "\n",
    "est = model.named_steps[\"est\"]\n",
    "importances = est.feature_importances_\n",
    "feature_names = model.named_steps[\"pre\"].get_feature_names_out()\n",
    "\n",
    "import pandas as pd\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": est.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36bb25a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['bat_speed_3yr_rolling' 'squared_up_rate_3yr_rolling'\n",
      " 'swing_length_3yr_rolling']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bengu\\AppData\\Local\\Temp\\ipykernel_25576\\3529197020.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batter_predictions_2026[f\"predicted_{target}\"] = y_pred\n",
      "c:\\Users\\bengu\\.virtualenvs\\cfeproj-oIABPDjj\\lib\\site-packages\\sklearn\\impute\\_base.py:653: UserWarning: Skipping features without any observed values: ['bat_speed_3yr_rolling' 'squared_up_rate_3yr_rolling'\n",
      " 'swing_length_3yr_rolling']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bengu\\AppData\\Local\\Temp\\ipykernel_25576\\3529197020.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batter_predictions_2026[f\"predicted_{target}\"] = y_pred\n"
     ]
    }
   ],
   "source": [
    "batter_predictions_2026 = post_statcast[post_statcast[\"season\"] == 2025]\n",
    "\n",
    "X_test = batter_predictions_2026.drop(exclude_cols, axis=1).reset_index(drop=True)\n",
    "\n",
    "for target in targets:\n",
    "    model = models[target]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    batter_predictions_2026[f\"predicted_{target}\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a616aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified = batter_predictions_2026[[\"fg_id\", \"player_name\", \"predicted_target_fWAR\", \"predicted_target_bWAR\"]]\n",
    "simplified.to_csv(\"2026 Batter WAR Projections.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfeproj-oIABPDjj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
